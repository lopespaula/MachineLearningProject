{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Dependencies to Visualize the model\n",
    "%matplotlib inline\n",
    "from IPython.display import Image, SVG\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Filepaths, numpy, and Tensorflow\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Sklearn scaling\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Keras Specific Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading and Preprocessing our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Load the MNIST Handwriting Dataset from Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Info\n",
      "Training Data Shape: (60000, 28, 28)\n",
      "Training Data Labels Shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "print(\"Training Data Info\")\n",
    "print(\"Training Data Shape:\", X_train.shape)\n",
    "print(\"Training Data Labels Shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Plot the first digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb29606cbe0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the first image from the dataset\n",
    "plt.imshow(X_train[0,:,:], cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Each Image is a 28x28 Pixel greyscale image with values from 0 to 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "          0,   0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,\n",
       "          1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "          0,  36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,\n",
       "          0,   3],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,\n",
       "          0, 102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,\n",
       "         10,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0, 155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,\n",
       "         72,  15],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "         69, 207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88,\n",
       "        172,  66],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0,\n",
       "        200, 232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196,\n",
       "        229,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        183, 225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245,\n",
       "        173,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        193, 228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243,\n",
       "        202,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12,\n",
       "        219, 220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197,\n",
       "        209,  52],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99,\n",
       "        244, 222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119,\n",
       "        167,  56],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55,\n",
       "        236, 228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,\n",
       "         92,   0],\n",
       "       [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237,\n",
       "        226, 217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,\n",
       "         77,   0],\n",
       "       [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228,\n",
       "        207, 213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244,\n",
       "        159,   0],\n",
       "       [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217,\n",
       "        226, 200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238,\n",
       "        215,   0],\n",
       "       [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200,\n",
       "        159, 245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232,\n",
       "        246,   0],\n",
       "       [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,\n",
       "         80, 150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228,\n",
       "        225,   0],\n",
       "       [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217,\n",
       "        241,  65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224,\n",
       "        229,  29],\n",
       "       [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198,\n",
       "        213, 240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221,\n",
       "        230,  67],\n",
       "       [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219,\n",
       "        221, 220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205,\n",
       "        206, 115],\n",
       "       [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211,\n",
       "        210, 200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177,\n",
       "        210,  92],\n",
       "       [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189,\n",
       "        188, 193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216,\n",
       "        170,   0],\n",
       "       [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244,\n",
       "        221, 220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our image is an array of pixels ranging from 0 to 255\n",
    "X_train[0, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### For training a model, we want to flatten our data into rows of 1D image arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: (60000, 784)\n",
      "Testing Shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# We want to flatten our image of 28x28 pixels to a 1D array of 784 pixels\n",
    "ndims = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], ndims)\n",
    "X_test = X_test.reshape(X_test.shape[0], ndims)\n",
    "print(\"Training Shape:\", X_train.shape)\n",
    "print(\"Testing Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Scaling and Normalization\n",
    "\n",
    "We use Sklearn's MinMaxScaler to normalize our data between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Next, we normalize our training data to be between 0 and 1\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# Alternative way to normalize this dataset since we know that the max pixel value is 255\n",
    "# X_train = X_train.astype(\"float32\")\n",
    "# X_test = X_test.astype(\"float32\")\n",
    "# X_train /= 255.0\n",
    "# X_test /= 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## One-Hot Encoding\n",
    "\n",
    "We need to one-hot encode our integer labels using the `to_categorical` helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, 3, 0, 2, 7, 2, 5, 5, 0, 9, 5, 5, 7, 9, 1, 0, 6, 4],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our Training and Testing labels are integer encoded from 0 to 9\n",
    "y_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to convert our target labels (expected values) to categorical data\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "# Original label of `5` is one-hot encoded as `0000010000`\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Building our Model\n",
    "\n",
    "In this example, we are going to build a Deep Multi-Layer Perceptron model with 2 hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our first step is to create an empty sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create an empty sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Next, we add our first hidden layer\n",
    "\n",
    "In the first hidden layer, we must also specify the dimension of our input layer. This will simply be the number of elements (pixels) in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Add the first layer where the input dimensions are the 784 pixel values\n",
    "# We can also choose our activation function. `relu` is a common\n",
    "model.add(Dense(100, activation='relu', input_dim=X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## We then add a second hidden layer with 100 densely connected nodes\n",
    "\n",
    "A dense layer is when every node from the previous layer is connected to each node in the current layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Add a second hidden layer\n",
    "model.add(Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our final output layer uses a `softmax` activation function for logistic regression.\n",
    "\n",
    "We also need to specify the number of output classes. In this case, the number of digits that we wish to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Add our final output layer where the number of nodes \n",
    "# corresponds to the number of y labels\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We can summarize our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compile and Train our Model\n",
    "\n",
    "Now that we have our model architecture defined, we must compile the model using a loss function and optimizer. We can also specify additional training metrics such as accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use categorical crossentropy for categorical data and mean squared error for regression\n",
    "# Hint: your output layer in this example is using software for logistic regression (categorical)\n",
    "# If your output layer activation was `linear` then you may want to use `mse` for loss\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Finally, we train our model using our training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Training consists of updating our weights using our optimizer and loss function. In this example, we choose 10 iterations (loops) of training that are called epochs.\n",
    "\n",
    "We also choose to shuffle our training data and increase the detail printed out during each training cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 - 7s - loss: 0.4928 - accuracy: 0.8242\n",
      "Epoch 2/10\n",
      "1875/1875 - 6s - loss: 0.3660 - accuracy: 0.8661\n",
      "Epoch 3/10\n",
      "1875/1875 - 7s - loss: 0.3327 - accuracy: 0.8773\n",
      "Epoch 4/10\n",
      "1875/1875 - 7s - loss: 0.3096 - accuracy: 0.8858\n",
      "Epoch 5/10\n",
      "1875/1875 - 6s - loss: 0.2936 - accuracy: 0.8914\n",
      "Epoch 6/10\n",
      "1875/1875 - 6s - loss: 0.2787 - accuracy: 0.8950\n",
      "Epoch 7/10\n",
      "1875/1875 - 6s - loss: 0.2671 - accuracy: 0.8997\n",
      "Epoch 8/10\n",
      "1875/1875 - 11s - loss: 0.2572 - accuracy: 0.9028\n",
      "Epoch 9/10\n",
      "1875/1875 - 7s - loss: 0.2480 - accuracy: 0.9061\n",
      "Epoch 10/10\n"
     ]
    }
   ],
   "source": [
    "# Fit (train) the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Saving and Loading models\n",
    "\n",
    "We can save our trained models using the HDF5 binary format with the extension `.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"mnist_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"mnist_trained.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "We use our testing data to validate our model. This is how we determine the validity of our model (i.e. the ability to predict new and previously unseen data points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model using the training data \n",
    "model_loss, model_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Making Predictions\n",
    "\n",
    "We can use our trained model to make predictions using `model.predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Grab just one data point to test with\n",
    "test = np.expand_dims(X_train[0], axis=0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(scaler.inverse_transform(test).reshape(28, 28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Make a prediction. The result should be 0000010000000 for a 5\n",
    "model.predict(test).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Grab just one data point to test with\n",
    "test = np.expand_dims(X_train[2], axis=0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(scaler.inverse_transform(test).reshape(28, 28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Make a prediction. The resulting class should match the digit\n",
    "print(f\"One-Hot-Encoded Prediction: {model.predict(test).round()}\")\n",
    "print(f\"Predicted class: {model.predict_classes(test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import a Custom Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"../Images/body.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "image_size = (28, 28)\n",
    "im = image.load_img(filepath, target_size=image_size, color_mode=\"grayscale\")\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the image to a numpy array \n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "image = img_to_array(im)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the image pixels by 255 (or use a scaler from sklearn here)\n",
    "image /= 255\n",
    "\n",
    "# Flatten into a 1x28*28 array \n",
    "img = image.flatten().reshape(-1, 28*28)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faaf2dc6d00>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7faaf362f220>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOyklEQVR4nO3db4xU9b3H8c8XpCrQIF5WXLfkgsWYgon8WZDEa0UbDWgMGFNSYqompDSCsU36QMJNxBgfEL2WNPGGhAoBbnppGouRB6IY/BdiNAwEFS9S1KBsXdlFgwUSBeR7H+zh3i3u+Z115swf+b5fyWZ2z2fPzpeBDzM758z8zN0F4Pw3pNkDAGgMyg4EQdmBICg7EARlB4K4oJFXNmbMGB8/fnwjrxII5eDBgzpy5IgNlNVUdjObI+kPkoZKetrdV6a+f/z48dq5c2ctVwkgYcaMGblZ1Q/jzWyopP+UNFfSJEkLzWxStT8PQH3V8jv7TEkfuPtH7n5S0p8lzStnLABlq6XsHZIO9fu6K9v2T8xssZlVzKzS29tbw9UBqEUtZR/oSYBvnXvr7mvcvdPdO9va2mq4OgC1qKXsXZLG9fv6R5I+rW0cAPVSS9l3SrrKzCaY2Q8k/ULSlnLGAlC2qg+9uftpM3tA0ovqO/S2zt3fK20yAKWq6Ti7uz8v6fmSZgFQR5wuCwRB2YEgKDsQBGUHgqDsQBCUHQiCsgNBUHYgCMoOBEHZgSAoOxAEZQeCoOxAEJQdCIKyA0FQdiAIyg4EQdmBICg7EARlB4Kg7EAQlB0IgrIDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBCUHQiipiWbzeygpGOSvpF02t07yxgKQPlqKnvmJnc/UsLPAVBHPIwHgqi17C5pm5ntMrPFA32DmS02s4qZVXp7e2u8OgDVqrXs17v7NElzJS01s5+e+w3uvsbdO929s62trcarA1Ctmsru7p9mlz2SnpU0s4yhAJSv6rKb2Qgz++HZzyXdKmlvWYMBKFctz8aPlfSsmZ39Of/t7i+UMhWA0lVddnf/SNK1Jc4CoI449AYEQdmBICg7EARlB4Kg7EAQlB0IgrIDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBCUHQiCsgNBUHYgCMoOBEHZgSAoOxAEZQeCoOxAEGUs7Hhe2LRpUzKfNWtWbnb06NHkvh0dHcl8//79yXzSpEnJ/KGHHsrNpk2bltx3yZIlyRznD+7ZgSAoOxAEZQeCoOxAEJQdCIKyA0FQdiAIjrNnLrvssmT++eef52ZnzpxJ7vvKK68k87Fjxybz1atXJ/MTJ07kZuvXr0/uy3H2OArv2c1snZn1mNneftsuNbOXzOxAdjm6vmMCqNVgHsavlzTnnG3LJG1396skbc++BtDCCsvu7q9L+uKczfMkbcg+3yBpfslzAShZtU/QjXX3bknKLnN/4TWzxWZWMbNKb29vlVcHoFZ1fzbe3de4e6e7d7a1tdX76gDkqLbsh82sXZKyy57yRgJQD9WWfYuke7PP75X0XDnjAKiXwuPsZrZJ0mxJY8ysS9IKSSsl/cXMFkn6RNLP6zlkI0ycODGZb9myJTe74oorkvveeuutyfypp55K5l9//XUyv/3223Oz1157Lbkv4igsu7svzIl+VvIsAOqI02WBICg7EARlB4Kg7EAQlB0Igpe4ZrZu3ZrMv/ji3JcH/L+iQ2OrVq1K5vfcc08yf/vtt5P5jBkzcrPdu3cn90Uc3LMDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBAcZ88UvZ3ztddem5tt27YtuW/Ry2eHDx+ezCdPnpzMDx8+nJvt3bs3N0Ms3LMDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBAcZ89cfvnlyTy1dNXs2bOT+27evDmZz5o1K5m/8cYbyfytt97KzR577LHkvvfdd18yL1ryGd8f3LMDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBAcZ898/PHHyXz16tW52eOPP57cd/78+cl86NChyfyzzz5L5nfddVduVqlUkvvOnDkzmeP8UXjPbmbrzKzHzPb22/aImf3dzPZkH7fVd0wAtRrMw/j1kuYMsH2Vu0/JPp4vdywAZSssu7u/Lil/7SMA3wu1PEH3gJm9kz3MH533TWa22MwqZlZJnV8OoL6qLftqST+WNEVSt6Qn877R3de4e6e7d7a1tVV5dQBqVVXZ3f2wu3/j7mck/VEST+kCLa6qsptZe78v75TE+xUDLa7wOLuZbZI0W9IYM+uStELSbDObIsklHZT06zrOWAp3T+bTp09P5nfccUduVvRa+P379yfzIUPS/+cW/fwHH3wwN0vNLUnt7e3J/OGHH07mjz76aDJH6ygsu7svHGDz2jrMAqCOOF0WCIKyA0FQdiAIyg4EQdmBIMK8xPXDDz9M5qdOnUrmt9xyS9U/+5prrknmXV1dyfzo0aPJ/O67787NbrjhhuS+b775ZjI/efJkMj9+/HgyHzlyZDJH43DPDgRB2YEgKDsQBGUHgqDsQBCUHQiCsgNBhDnOfuLEiWQ+atSoZJ56iezTTz9d9b6StGDBgmQ+derUZD5hwoTc7MUXX0zue+DAgWR+ySWXJPMnn8x9kyJJ0ooVK5I5God7diAIyg4EQdmBICg7EARlB4Kg7EAQlB0IIsxx9l27diXzjo6OZD5ixIjcbPny5cl9X3311WR+0UUXJfOiZbMuuCD/r/Hll19O7nvdddcl8zvvvDOZ79y5M5mnlrq+//77k/uiXNyzA0FQdiAIyg4EQdmBICg7EARlB4Kg7EAQVvRa6zJ1dnZ60XHZejGzZL5kyZJkPnHixNzshRdeSO6bWlJZkj755JNkftNNNyXz1HH+J554Irlvd3d3Mh82bFgyv/DCC5N56vyGK6+8Mrlv0Z8b3zZjxgxVKpUB/7EX3rOb2Tgze8XM9pnZe2b2m2z7pWb2kpkdyC5Hlz04gPIM5mH8aUm/c/efSJolaamZTZK0TNJ2d79K0vbsawAtqrDs7t7t7ruzz49J2iepQ9I8SRuyb9sgaX69hgRQu+/0BJ2ZjZc0VdJbksa6e7fU9x+CpMty9llsZhUzqxSd4w2gfgZddjMbKemvkn7r7v8Y7H7uvsbdO929s62trZoZAZRgUGU3s2HqK/qf3H1ztvmwmbVnebuknvqMCKAMhS9xtb5jVmsl7XP33/eLtki6V9LK7PK5ukxYkjNnziTzosNnF198cW721Vdf1fSzDx06lMx7etL/j6YOj1UqleS+N998czJ/5plnknnRctQ33nhjbrZx48bkvseOHUvmV199dTL/8ssvc7Pp06cn9x06dGgy/z4azOvZr5f0S0nvmtmebNty9ZX8L2a2SNInkn5enxEBlKGw7O6+Q1LeGSk/K3ccAPXC6bJAEJQdCIKyA0FQdiAIyg4EEeatpIte4lq0NPGpU6dys6KXCS9atCiZT5kyJZkXWbYs/zVIRW9znXqrZ0maM2dOMu/q6krmqVOki14+W3S7nj59OpmvXbs2N3v//feT+06ePDmZF/25582bl8ybgXt2IAjKDgRB2YEgKDsQBGUHgqDsQBCUHQgizHH2ImPGjEnmqddGF71W/sSJE1XNNFgrV66sKpOK32q66M+2devWZL5gwYLcbMeOHcl9i46Fz507N5mnzq0omrvotfZFt1sr4p4dCIKyA0FQdiAIyg4EQdmBICg7EARlB4IIs2RzkYULFybz4cOH52ZF72/e0dGRzFetWpXMi9Tz77DoZ48aNSqZp84xuOCC9GkeS5cuTeZF5xCkfv6QIbXdzxW9P0Kz1LRkM4DzA2UHgqDsQBCUHQiCsgNBUHYgCMoOBDGY9dnHSdoo6XJJZyStcfc/mNkjkn4l6ewbgy939+frNWi9bdq0qdkjVK2ex3yLfnbROQZoHYN584rTkn7n7rvN7IeSdpnZS1m2yt3/o37jASjLYNZn75bUnX1+zMz2SUqfEgag5Xyn39nNbLykqZLeyjY9YGbvmNk6Mxuds89iM6uYWSW1FBCA+hp02c1spKS/Svqtu/9D0mpJP5Y0RX33/E8OtJ+7r3H3TnfvbGtrK2FkANUYVNnNbJj6iv4nd98sSe5+2N2/cfczkv4oaWb9xgRQq8KyW9/TsWsl7XP33/fb3t7v2+6UtLf88QCUZTDPxl8v6ZeS3jWzPdm25ZIWmtkUSS7poKRf12VCAKUYzLPxOyQNdLD1e3tMHYiIM+iAICg7EARlB4Kg7EAQlB0IgrIDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBCUHQiCsgNBNHTJZjPrlfRxv01jJB1p2ADfTavO1qpzScxWrTJn+1d3H/D93xpa9m9duVnF3TubNkBCq87WqnNJzFatRs3Gw3ggCMoOBNHssq9p8vWntOpsrTqXxGzVashsTf2dHUDjNPueHUCDUHYgiKaU3czmmNl+M/vAzJY1Y4Y8ZnbQzN41sz1mVmnyLOvMrMfM9vbbdqmZvWRmB7LLAdfYa9Jsj5jZ37Pbbo+Z3dak2caZ2Stmts/M3jOz32Tbm3rbJeZqyO3W8N/ZzWyopL9JukVSl6Sdkha6+/80dJAcZnZQUqe7N/0EDDP7qaTjkja6+zXZtsclfeHuK7P/KEe7+0MtMtsjko43exnvbLWi9v7LjEuaL+k+NfG2S8y1QA243Zpxzz5T0gfu/pG7n5T0Z0nzmjBHy3P31yV9cc7meZI2ZJ9vUN8/lobLma0luHu3u+/OPj8m6ewy40297RJzNUQzyt4h6VC/r7vUWuu9u6RtZrbLzBY3e5gBjHX3bqnvH4+ky5o8z7kKl/FupHOWGW+Z266a5c9r1YyyD7SUVCsd/7ve3adJmitpafZwFYMzqGW8G2WAZcZbQrXLn9eqGWXvkjSu39c/kvRpE+YYkLt/ml32SHpWrbcU9eGzK+hmlz1Nnuf/tNIy3gMtM64WuO2aufx5M8q+U9JVZjbBzH4g6ReStjRhjm8xsxHZEycysxGSblXrLUW9RdK92ef3SnquibP8k1ZZxjtvmXE1+bZr+vLn7t7wD0m3qe8Z+Q8l/XszZsiZ60pJb2cf7zV7Nkmb1Pew7pT6HhEtkvQvkrZLOpBdXtpCs/2XpHclvaO+YrU3abZ/U9+vhu9I2pN93Nbs2y4xV0NuN06XBYLgDDogCMoOBEHZgSAoOxAEZQeCoOxAEJQdCOJ/AU5bkYFl2Ne7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Invert the pixel values to match the original data\n",
    "img = 1 - img\n",
    "plt.imshow(img.reshape(28, 28), cmap=plt.cm.Greys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
